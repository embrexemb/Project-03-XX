{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Gaussian Processes regression: basic introductory example\n",
    "\n",
    "A simple one-dimensional regression example computed in two different ways:\n",
    "\n",
    "1. A noise-free case\n",
    "2. A noisy case with known noise-level per datapoint\n",
    "\n",
    "In both cases, the kernel's parameters are estimated using the maximum\n",
    "likelihood principle.\n",
    "\n",
    "The figures illustrate the interpolating property of the Gaussian Process\n",
    "model as well as its probabilistic nature in the form of a pointwise 95%\n",
    "confidence interval.\n",
    "\n",
    "Note that the parameter ``alpha`` is applied as a Tikhonov\n",
    "regularization of the assumed covariance between the training points.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "print(__doc__)\n",
    "\n",
    "# Author: Vincent Dubourg <vincent.dubourg@gmail.com>\n",
    "#         Jake Vanderplas <vanderplas@astro.washington.edu>\n",
    "#         Jan Hendrik Metzen <jhm@informatik.uni-bremen.de>s\n",
    "# License: BSD 3 clause\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, ConstantKernel as C\n",
    "\n",
    "np.random.seed(1)\n",
    "\n",
    "\n",
    "def f(x):\n",
    "    \"\"\"The function to predict.\"\"\"\n",
    "    return x * np.sin(x)\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "#  First the noiseless case\n",
    "X = np.atleast_2d([1., 3., 5., 6., 7., 8.]).T\n",
    "\n",
    "# Observations\n",
    "y = f(X).ravel()\n",
    "\n",
    "# Mesh the input space for evaluations of the real function, the prediction and\n",
    "# its MSE\n",
    "x = np.atleast_2d(np.linspace(0, 10, 1000)).T\n",
    "\n",
    "# Instantiate a Gaussian Process model\n",
    "kernel = C(1.0, (1e-3, 1e3)) * RBF(10, (1e-2, 1e2))\n",
    "gp = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=9)\n",
    "\n",
    "# Fit to data using Maximum Likelihood Estimation of the parameters\n",
    "gp.fit(X, y)\n",
    "\n",
    "# Make the prediction on the meshed x-axis (ask for MSE as well)\n",
    "y_pred, sigma = gp.predict(x, return_std=True)\n",
    "\n",
    "# Plot the function, the prediction and the 95% confidence interval based on\n",
    "# the MSE\n",
    "plt.figure()\n",
    "plt.plot(x, f(x), 'r:', label=r'$f(x) = x\\,\\sin(x)$')\n",
    "plt.plot(X, y, 'r.', markersize=10, label='Observations')\n",
    "plt.plot(x, y_pred, 'b-', label='Prediction')\n",
    "plt.fill(np.concatenate([x, x[::-1]]),\n",
    "         np.concatenate([y_pred - 1.9600 * sigma,\n",
    "                        (y_pred + 1.9600 * sigma)[::-1]]),\n",
    "         alpha=.5, fc='b', ec='None', label='95% confidence interval')\n",
    "plt.xlabel('$x$')\n",
    "plt.ylabel('$f(x)$')\n",
    "plt.ylim(-10, 20)\n",
    "plt.legend(loc='upper left')\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# now the noisy case\n",
    "X = np.linspace(0.1, 9.9, 20)\n",
    "X = np.atleast_2d(X).T\n",
    "\n",
    "# Observations and noise\n",
    "y = f(X).ravel()\n",
    "dy = 0.5 + 1.0 * np.random.random(y.shape)\n",
    "noise = np.random.normal(0, dy)\n",
    "y += noise\n",
    "\n",
    "# Instantiate a Gaussian Process model\n",
    "gp = GaussianProcessRegressor(kernel=kernel, alpha=dy ** 2,\n",
    "                              n_restarts_optimizer=10)\n",
    "\n",
    "# Fit to data using Maximum Likelihood Estimation of the parameters\n",
    "gp.fit(X, y)\n",
    "\n",
    "# Make the prediction on the meshed x-axis (ask for MSE as well)\n",
    "y_pred, sigma = gp.predict(x, return_std=True)\n",
    "\n",
    "# Plot the function, the prediction and the 95% confidence interval based on\n",
    "# the MSE\n",
    "plt.figure()\n",
    "plt.plot(x, f(x), 'r:', label=r'$f(x) = x\\,\\sin(x)$')\n",
    "plt.errorbar(X.ravel(), y, dy, fmt='r.', markersize=10, label='Observations')\n",
    "plt.plot(x, y_pred, 'b-', label='Prediction')\n",
    "plt.fill(np.concatenate([x, x[::-1]]),\n",
    "         np.concatenate([y_pred - 1.9600 * sigma,\n",
    "                        (y_pred + 1.9600 * sigma)[::-1]]),\n",
    "         alpha=.5, fc='b', ec='None', label='95% confidence interval')\n",
    "plt.xlabel('$x$')\n",
    "plt.ylabel('$f(x)$')\n",
    "plt.ylim(-10, 20)\n",
    "plt.legend(loc='upper left')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-Machine_Learning]",
   "language": "python",
   "name": "conda-env-.conda-Machine_Learning-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
